import argparse
import datetime
import getpass
import os
import pathlib
import subprocess
import tempfile
from dataclasses import dataclass
from typing import Optional

import yaml

from gigl.common import GcsUri, UriFactory
from gigl.src.common.utils.file_loader import FileLoader

GIGL_ROOT_DIR = pathlib.Path(__file__).resolve().parent.parent
CURR_DATETIME = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
CURR_USERNAME = getpass.getuser()


@dataclass
class Param:
    default: Optional[str]
    description: str
    long_description: str = ""
    required: bool = True


@dataclass
class TemplateConfig:
    template_path: pathlib.Path
    env_var_to_update: str

    def __post_init__(self):
        if not self.template_path.exists():
            raise FileNotFoundError(f"Template file not found: {self.template_path}")


# Template configurations to process
TEMPLATE_CONFIGS = {
    "default": TemplateConfig(
        template_path=GIGL_ROOT_DIR
        / "deployment"
        / "configs"
        / "e2e_cicd_resource_config.yaml",
        env_var_to_update="GIGL_TEST_DEFAULT_RESOURCE_CONFIG",
    ),
    "in_memory": TemplateConfig(
        template_path=GIGL_ROOT_DIR
        / "deployment"
        / "configs"
        / "e2e_glt_resource_config.yaml",
        env_var_to_update="GIGL_TEST_IN_MEMORY_DEFAULT_RESOURCE_CONFIG",
    ),
}


class SupportedParams:
    def __init__(self):
        try:
            project = subprocess.check_output(
                ["gcloud", "config", "get-value", "project"], text=True
            ).strip()
        except subprocess.CalledProcessError as e:
            print(
                "Error retrieving active project name; is your gcloud SDK configured correctly?",
                e,
            )
            raise
        self.defaults: dict[str, Param] = {
            "project": Param(
                default=project,
                description="GCP Project name that you are planning on using",
            ),
            "region": Param(
                default="us-central1",
                description="The GCP region where you created your resources",
            ),
            "gcp_service_account_email": Param(
                default=None, description="The GCP Service account"
            ),
            "docker_artifact_registry_path": Param(
                default=None,
                description="The Docker Artifact Registry path where your source code images will be stored i.e. `us-central1-docker.pkg.dev/YOUR_PROJECT_NAME/YOUR_REPO_NAME`",
            ),
            "temp_assets_bq_dataset_name": Param(
                default=None,
                description="`temp_assets_bq_dataset_name` - Dataset name used for temporary assets",
            ),
            "embedding_bq_dataset_name": Param(
                default=None,
                description="`embedding_bq_dataset_name` - Dataset used of output embeddings",
            ),
            "temp_assets_bucket": Param(
                default=None,
                description="`temp_assets_bucket` - GCS Bucket for storing temporary assets i.e. `gs://YOUR_BUCKET_NAME`",
            ),
            "perm_assets_bucket": Param(
                default=None,
                description="`perm_assets_bucket` - GCS Bucket for storing permanent assets i.e. `gs://YOUR_BUCKET_NAME`",
            ),
        }


def compute_resource_config_destination_path(
    name: str,
    perm_assets_bucket: str,
) -> GcsUri:
    return GcsUri(
        f"{perm_assets_bucket}/{CURR_USERNAME}/{CURR_DATETIME}/{name}_resource_config.yaml"
    )


def infer_shell_file() -> str:
    """Infers the user's default shell configuration file."""
    shell = os.environ.get("SHELL", "")
    shell_config_map = {
        "zsh": "~/.zshrc",
        "bash": "~/.bashrc",
    }

    for key, config_file in shell_config_map.items():
        if key in shell:
            print(f"Detected shell: {key}. Using config file: {config_file}")
            return config_file

    print(
        "Could not infer the default shell. Please specify the shell configuration file manually."
    )
    return input(
        "Enter the path to your shell configuration file (e.g., ~/.bashrc): "
    ).strip()


def update_shell_config(
    shell_config_path: str,
    shell_env_vars: dict[str, str],
):
    """Updates the shell configuration file with the environment variables in an idempotent way."""
    shell_config_path = os.path.expanduser(shell_config_path)
    start_marker = "# ====== GiGL ENV Config - Begin ====="
    end_marker = "# ====== GiGL ENV Config - End ====="
    export_lines = [
        f'export {key}="{value}"\n' for key, value in shell_env_vars.items()
    ]
    export_lines = (
        [
            start_marker + "\n",
            "# This section is auto-generated by GiGL/scripts/bootstrap_resource_config.py.\n",
        ]
        + export_lines
        + [
            end_marker + "\n",
        ]
    )

    # Read the existing shell config file
    if not os.path.exists(shell_config_path):
        raise FileNotFoundError(
            f"Shell config file '{shell_config_path}' does not exist."
        )
    shell_config_lines: list[str]
    with open(shell_config_path, "r") as shell_config:
        shell_config_lines = shell_config.readlines()

    inside_block = False
    updated_shell_config_lines = []
    for line in shell_config_lines:
        if line.strip().startswith(start_marker):
            inside_block = True
        elif line.strip().startswith(end_marker):
            inside_block = False
            continue
        if not inside_block:
            updated_shell_config_lines.append(line)

    # Add the new GiGL config block
    updated_shell_config_lines.extend(export_lines)

    # Write back to the shell config file
    with open(shell_config_path, "w") as shell_config:
        shell_config.writelines(updated_shell_config_lines)

    print(f"Updated {shell_config_path} with:\n{export_lines}.")


def assert_gcp_project_exists(project_id: str):
    command = f"gcloud projects describe {project_id}"
    result = subprocess.run(command, shell=True, capture_output=True, text=True)

    print(result.stdout)
    if result.returncode != 0:
        print(f"Command `{command}` failed with error: {result.stderr}")
        raise ValueError(
            f"Project '{project_id}' does not exist or you do not have access to it."
        )


def assert_bq_dataset_exists(dataset_name: str, project: str):
    command = f"bq show --project_id {project} {dataset_name}"
    result = subprocess.run(command, shell=True, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"Command `{command}` failed with error: {result.stderr}")
        raise ValueError(
            f"BigQuery dataset '{dataset_name}' does not exist in project '{project}' or you do not have access to it."
        )
    print(f"Confirmed BigQuery dataset '{dataset_name}' exists.")


def assert_gcs_bucket_exists(bucket_name: str):
    assert bucket_name.startswith("gs://"), "Bucket name must start with 'gs://'"
    command = f"gsutil ls {bucket_name}"
    result = subprocess.run(command, shell=True, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"Command `{command}` failed with error: {result.stderr}")
        raise ValueError(
            f"GCS bucket '{bucket_name}' does not exist or you do not have access to it."
        )
    print(f"Confirmed GCS bucket '{bucket_name}' exists.")


if __name__ == "__main__":
    print("Welcome to the GiGL Cloud Environment Configuration Script!")
    print("This script will help you set up your cloud environment for GiGL.")
    print(
        "Before running this script, please ensure you have followed the GiGL Cloud Setup Guide:"
    )
    print(
        "https://snapchat.github.io/GiGL/docs/user_guide/getting_started/cloud_setup_guide"
    )
    print("======================================================")

    supported_params = SupportedParams()
    parser = argparse.ArgumentParser(
        description="Bootstrap GiGL resource config. All parameters can be provided as CLI args or interactively."
    )
    for key, param in supported_params.defaults.items():
        help_text = (
            f"{param.description} (default: {param.default})"
            if param.default
            else param.description
        )
        parser.add_argument(f"--{key}", type=str, help=help_text)
    args = parser.parse_args()

    values: dict[str, str] = {}
    for key, param in supported_params.defaults.items():
        # Check if value is provided in command line arguments
        if getattr(args, key):
            values[key] = getattr(args, key)
            continue
        # If not, prompt for input
        else:
            input_question: str
            long_description_clause = (
                f"\n{param.long_description}" if param.long_description else ""
            )
            if param.default is None:
                required_clause = "(required)" if param.required else "(optional)"
                input_question = f"-> {param.description}{long_description_clause} {required_clause}: "
            else:
                input_question = f"-> {param.description}{long_description_clause}\nDefaults to: [{param.default}]: "

            values[key] = input(input_question).strip() or param.default  # type: ignore
            if not values[key] and param.required:
                raise ValueError(
                    f"Missing required value for {key}. Please provide a value."
                )

    # Validate existence of resources
    assert_gcp_project_exists(values["project"])
    assert values["region"], "Region cannot be empty"
    assert values["gcp_service_account_email"], "GCP Service account cannot be empty"
    assert values[
        "docker_artifact_registry_path"
    ], "Docker Artifact Registry path cannot be empty"
    assert_bq_dataset_exists(
        dataset_name=values["temp_assets_bq_dataset_name"], project=values["project"]
    )
    assert_bq_dataset_exists(
        dataset_name=values["embedding_bq_dataset_name"], project=values["project"]
    )
    assert_gcs_bucket_exists(bucket_name=values["temp_assets_bucket"])
    assert_gcs_bucket_exists(bucket_name=values["perm_assets_bucket"])

    update_fields_dict = {
        "project": values["project"],
        "region": values["region"],
        "gcp_service_account_email": values["gcp_service_account_email"],
        "temp_assets_bucket": values["temp_assets_bucket"],
        "temp_regional_assets_bucket": values["temp_assets_bucket"],
        "perm_assets_bucket": values["perm_assets_bucket"],
        "temp_assets_bq_dataset_name": values["temp_assets_bq_dataset_name"],
        "embedding_bq_dataset_name": values["embedding_bq_dataset_name"],
    }
    print("=======================================================")
    print("Will now create the resource config files:")
    for key, value in update_fields_dict.items():
        print(f"  {key}: {value}")

    file_loader = FileLoader(project=values["project"])
    for name, config in TEMPLATE_CONFIGS.items():
        resource_config_destination_path = compute_resource_config_destination_path(
            perm_assets_bucket=values["perm_assets_bucket"], name=name
        )

        with open(config.template_path, "r") as file:
            config = yaml.safe_load(file)

        # Update the YAML content
        common_compute_config: dict = config.get("shared_resource_config").get(
            "common_compute_config"
        )
        common_compute_config.update(update_fields_dict)

        tmp_file = tempfile.NamedTemporaryFile(delete=False)
        with open(tmp_file.name, "w") as file:
            yaml.safe_dump(config, file)

        file_loader = FileLoader(project=values["project"])
        file_uri_src = UriFactory.create_uri(uri=tmp_file.name)
        file_loader.load_file(
            file_uri_src=file_uri_src, file_uri_dst=resource_config_destination_path
        )

    shell_env_vars = {
        "GIGL_PROJECT": values["project"],
        "GIGL_DOCKER_ARTIFACT_REGISTRY": values["docker_artifact_registry_path"],
    }
    for name, config in TEMPLATE_CONFIGS.items():
        shell_env_vars[config.env_var_to_update] = resource_config_destination_path.uri
    # Update the user's shell configuration (always)
    print("Updating shell configuration...")
    shell_config_path: str = infer_shell_file()
    update_shell_config(
        shell_config_path=shell_config_path,
        shell_env_vars=shell_env_vars,
    )

    print(
        f"Shell configuration updated. Please restart your shell or run `source {shell_config_path}` to apply the changes."
    )
