# Template config for an example heterogeneous graph.

# Note that you should run this template config through the config_populator
# component to generate a frozen config, which contains the required fields for where assets will be written. You can do this as
# part of an E2E VAI pipeline or by calling the config populator directly by running:
# python -m \
#    gigl.src.config_populator.config_populator \
#    --job_name="example_job_name" \
#    --template_uri="gigl/examples/tutorial/KDD_2025/task_config.yaml" \
#    --resource_config_uri="gigl/examples/tutorial/KDD_2025/resource_config.yaml" \
#    --output_file_path_frozen_gbml_config_uri="gigl/examples/tutorial/KDD_2025/example_output_path.yaml"

# ========
# TaskMetadata:
# Specifies the task we are going to perform on the graph.
taskMetadata:
  nodeAnchorBasedLinkPredictionTaskMetadata:
    # Specifying that we will perform node anchor based link prediction on edge of type: user -> to -> story
    supervisionEdgeTypes:
    - dstNodeType: story
      relation: to
      srcNodeType: user
graphMetadata:
  # We have 2 nodes types in the toy dataset: user and story. We also have 2
  # edge types: user -> to -> story and story -> to -> user
  edgeTypes:
  - dstNodeType: user
    relation: to
    srcNodeType: story
  - dstNodeType: story
    relation: to
    srcNodeType: user
  nodeTypes:
  - user
  - story
# ========
# SharedConfig:
# Specifies some extra metadata about the graph structure management of orchestration.
sharedConfig:
  shouldSkipAutomaticTempAssetCleanup: true # Should we skip cleaning up the temporary assets after the run is complete?
# ========
# DatasetConfig:
# Specifies information about the dataset, such as how to access it and how to process it
datasetConfig:
  dataPreprocessorConfig:
    dataPreprocessorArgs:
      # We specify the mocked bigquery node and edge tables for the toy dataset through the dataPreprocessorArgs field.
      # These specific toy graph BQ tables can be generated by running the mocker with `make mock_assets`
      bq_user_node_table_name: external-snap-ci-github-gigl.public_gigl.toy_graph_heterogeneous_node_anchor_lp_user_nodes_2025-07-24--20-45-44-UTC
      bq_story_node_table_name: external-snap-ci-github-gigl.public_gigl.toy_graph_heterogeneous_node_anchor_lp_story_nodes_2025-07-24--20-45-44-UTC
      bq_user_story_edge_table_name: external-snap-ci-github-gigl.public_gigl.toy_graph_heterogeneous_node_anchor_lp_user-to-story_edges_main_2025-07-24--20-45-44-UTC
      bq_story_user_edge_table_name: external-snap-ci-github-gigl.public_gigl.toy_graph_heterogeneous_node_anchor_lp_story-to-user_edges_main_2025-07-24--20-45-44-UTC
    dataPreprocessorConfigClsPath: examples.tutorial.KDD_2025.preprocessor_config.ToyDataPreprocessorConfig


# ========
# TrainerConfig:
# Specifies the training configuration. This includes the trainer command and the arguments to pass to it.
trainerConfig:
  trainerArgs:
    # Example argument to trainer
    log_every_n_batch: "50"
    # These arguements are read by `build_dataset_from_task_config_uri`.
    ssl_positive_label_percentage: "0.7"
    num_val: "0.3"
    num_test: "0.3"
  command: python -m gigl.examples.tutorial.KDD_2025.heterogeneous_training
# ========
# InferencerConfig:
# specifies the inference configuration. This includes the inferencer command and the arguments to pass to it
inferencerConfig:
  inferencerArgs:
    # Example argument to inferencer
    log_every_n_batch: "50"
  inferenceBatchSize: 4
  command: python -m gigl.examples.tutorial.KDD_2025.heterogeneous_inference
# ========
# FeatureFlags:
# any additional flags which we should specify for the training + inference job. We currently use this to
# specify whether GLT should be used as the backend for in-memory subgraph sampling
featureFlags:
  should_run_glt_backend: 'True'
