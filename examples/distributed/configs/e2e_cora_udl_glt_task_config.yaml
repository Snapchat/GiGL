graphMetadata:
  edgeTypes:
  - dstNodeType: paper
    relation: cites
    srcNodeType: paper
  nodeTypes:
  - paper
datasetConfig:
  dataPreprocessorConfig:
    dataPreprocessorConfigClsPath: gigl.src.mocking.mocking_assets.passthrough_preprocessor_config_for_mocked_assets.PassthroughPreprocessorConfigForMockedAssets
    dataPreprocessorArgs:
      # This argument is specific for the `PassthroughPreprocessorConfigForMockedAssets` preprocessor to indicate which dataset we should be using
      mocked_dataset_name: 'cora_homogeneous_node_anchor_edge_features_user_defined_labels'
trainerConfig:
  trainerArgs:
    # Example argument to trainer
    log_every_n_batch: "50"
  command: python -m examples.distributed.homogeneous_training
inferencerConfig:
  inferencerArgs:
    # Example argument to inferencer
    log_every_n_batch: "50"
  inferenceBatchSize: 512
  command: python -m examples.distributed.homogeneous_inference
sharedConfig:
  shouldSkipAutomaticTempAssetCleanup: false
  shouldSkipInference: false
  # Model Evaluation is only applicable for V1 GiGL -- we do not need it for V2
  shouldSkipModelEvaluation: true
  trainedModelMetadata:
    # This is an example model trained on the CORA dataset. To train a custom CORA model, please refer to the
    # `gigl/src/mocking/configs/e2e_udl_node_anchor_based_link_prediction_template_gbml_config.yaml` config template.
    # You can run a pipeline for training on CORA using `make run_cora_udl_e2e_kfp_test`.
    trainedModelUri: gs://public-gigl/mocked_assets/2024-07-15--21-30-07-UTC/cora_homogeneous_node_anchor_edge_features_user_defined_labels/trainer/models/model.pt
taskMetadata:
  nodeAnchorBasedLinkPredictionTaskMetadata:
    supervisionEdgeTypes:
    - dstNodeType: paper
      relation: cites
      srcNodeType: paper
featureFlags:
  should_run_glt_backend: 'True'
  data_preprocessor_num_shards: '2'
