graphMetadata:
  edgeTypes:
  - dstNodeType: paper
    relation: cites
    srcNodeType: paper
  nodeTypes:
  - paper
datasetConfig:
  dataPreprocessorConfig:
    dataPreprocessorConfigClsPath: gigl.src.mocking.mocking_assets.passthrough_preprocessor_config_for_mocked_assets.PassthroughPreprocessorConfigForMockedAssets
    dataPreprocessorArgs:
      # This argument is specific for the `PassthroughPreprocessorConfigForMockedAssets` preprocessor to indicate which dataset we should be using
      mocked_dataset_name: 'cora_homogeneous_node_anchor_edge_features_user_defined_labels'
trainerConfig:
  trainerArgs:
    # Example argument to trainer
    log_every_n_batch: "50"
  command: python -m examples.distributed.homogeneous_training
inferencerConfig:
  inferencerArgs:
    # Example argument to inferencer
    log_every_n_batch: "50"
  inferenceBatchSize: 512
  command: python -m examples.distributed.homogeneous_inference
sharedConfig:
  shouldSkipAutomaticTempAssetCleanup: false
  shouldSkipInference: false
  # Model Evaluation is currently only supported for offline SGS priplines. This will soon be added for live SGS pipelines using GLT.
  shouldSkipModelEvaluation: true
taskMetadata:
  nodeAnchorBasedLinkPredictionTaskMetadata:
    supervisionEdgeTypes:
    - dstNodeType: paper
      relation: cites
      srcNodeType: paper
featureFlags:
  should_run_glt_backend: 'True'
  data_preprocessor_num_shards: '2'
